#!/usr/bin/env python3

# Copyright Â© 2022 Jakub Wilk <jwilk@jwilk.net>
# SPDX-License-Identifier: MIT

import argparse
import contextlib
import gzip
import http.client
import inspect
import io
import json
import os
import re
import shutil
import signal
import subprocess
import sys
import textwrap
import types
import urllib.parse
import urllib.request

import html2text

0_0  # Python >= 3.6 is required

prog = argparse.ArgumentParser().prog

def find_command(command):
    if shutil.which(command):
        return command

def fatal(msg):
    print(f'{prog}: {msg}', file=sys.stderr)
    sys.exit(1)

class StdOut(io.TextIOBase):

    def _install_pager(self):
        if not sys.__stdout__.isatty():
            return
        cmdline = (os.environ.get('PAGER')
            or find_command('pager')  # Debian <https://www.debian.org/doc/debian-policy/ch-customized-programs.html#editors-and-pagers>
            or 'more'  # POSIX <https://pubs.opengroup.org/onlinepubs/007904975/utilities/man.html#tag_04_85_08>
        )
        if cmdline == 'cat':
            return
        env = None
        if 'LESS' not in os.environ:
            env = dict(env or os.environ, LESS='-FXK')
        self._pager = subprocess.Popen(cmdline, shell=True, stdin=subprocess.PIPE, env=env)
        encoding = sys.__stdout__.encoding
        self._stdout = io.TextIOWrapper(self._pager.stdin, encoding=encoding, line_buffering=True)

    def __init__(self):
        self._newlines = 0
        self._pager = None
        self._stdout = sys.__stdout__
        self._install_pager()

    def _get_fp(self):
        if UserAgent.debug_level:
            # Redirect http.client's debug messages to stderr:
            for frameinfo in inspect.stack(context=0):
                if frameinfo.filename == http.client.__file__:
                    return sys.__stderr__
        return self._stdout

    def write(self, s):
        fp = self._get_fp()
        if fp is self._stdout:
            if s == '':
                return
            if s == '\n':
                if self._newlines == 2:
                    return
                self._newlines += 1
            else:
                self._newlines = int(s[-1] == '\n')
        fp.write(s)

    def flush(self):
        self._get_fp().flush()

    def isatty(self):
        if self._pager is not None:
            return 'pager'
        return False

    def __exit__(self, exc_type, exc_value, traceback):
        if self._pager:
            self._pager.__exit__(exc_type, exc_value, traceback)
            if exc_type is None and self._pager.returncode != 0:
                raise RuntimeError('pager failed')
            self._pager = None
            self._stdout = None

    @staticmethod
    @contextlib.contextmanager
    def install():
        assert sys.stdout is sys.__stdout__
        try:
            with StdOut() as sys.stdout:
                yield
        finally:
            sys.stdout = sys.__stdout__

class UserAgent():

    headers = {
        'User-Agent': 'zygolophodon (https://github.com/jwilk/zygolophodon)',
        'Accept-Encoding': 'gzip',
    }
    debug_level = 0

    @classmethod
    def _build_opener(cls):
        # TODO: Get rid of this function once
        # <https://github.com/python/cpython/issues/99352> is fixed.
        handlers = [
            Handler(debuglevel=cls.debug_level)
            for Handler in [urllib.request.HTTPHandler, urllib.request.HTTPSHandler]
        ]
        return urllib.request.build_opener(*handlers)

    @classmethod
    def get(cls, url):
        headers = dict(cls.headers)
        request = urllib.request.Request(url, headers=headers)
        opener = cls._build_opener()
        response = opener.open(request)
        return Response(response)

class Response(object):

    def __init__(self, response):
        with response:
            content_encoding = response.getheader('Content-Encoding', 'identity')
            data = response.read()
        if content_encoding == 'gzip':
            data = gzip.decompress(data)
        elif content_encoding == 'identity':
            pass
        else:
            raise RuntimeError(f'unexpected Content-Encoding: {content_encoding!r}')
        self.data = data
        self.headers = response.headers

    @property
    def json(self):
        return json.loads(self.data, object_hook=DictProxy)

wget = UserAgent.get

def wget_json(url):
    return wget(url).json

class DictProxy(object):

    def __init__(self, d):
        self._d = d

    def __getattr__(self, attr):
        return self._d[attr]

def fmt_url(url):
    if sys.stdout.isatty() == 'pager':
        return re.sub('(.)', r'_\b\1', url)
    return url

def fmt_user(account):
    return f'{account.display_name} <{fmt_url(account.url)}>'.lstrip()

def fmt_date(d):
    d = re.sub(r'[.]\d+', '', d)
    d = d.replace('T', ' ')
    return d

def clean_html(html):
    # TODO: use a proper HTML parser?
    return re.sub(r'<span class="(?:invisible|ellipsis)">([^<]*)</span>', r'\1', html)

def fmt_html(html):
    html = clean_html(html)
    html2md = html2text.HTML2Text()
    html2md.unicode_snob = True
    text = html2md.handle(html)
    return text.strip('\n')

class URLParser(object):

    def __init__(self, *templates):
        self.templates = []
        self._groups = set()
        self._regexps = []
        for template in templates:
            self._add_template(f'https://DOMAIN/{template}')

    def _add_template(self, template):
        self.templates += [template]
        group2regexp = dict(
            domain='[^/]+',
            user='[^/]+',
            ident='[0-9]+',
        )
        def repl(match):
            s = match.group()
            if match.start() == 0 and s == 'https':
                return s
            if s.isupper():
                group = s.lower()
                if group == 'nnnnnn':
                    group = 'ident'
                regexp = group2regexp[group]
            else:
                group = s
                regexp = re.escape(s)
            self._groups.add(group)
            return f'(?P<{group}>{regexp})'
        regexp = re.sub(r'\w+', repl, template)
        regexp = re.compile(regexp)
        self._regexps += [regexp]

    def parse(self, url):
        for regexp in self._regexps:
            match = re.fullmatch(regexp, url)
            if match is not None:
                break
        else:
            return
        data = {group: None for group in self._groups}
        data.update(match.groupdict())
        return types.SimpleNamespace(**data)

def pint(s):
    n = int(s)
    if n > 0:
        return n
    else:
        raise ValueError
pint.__name__ = 'positive int'

def xmain():
    url_parser = URLParser(
        'statuses/NNNNNN',
        '@USER/NNNNNN',
        '@USER/NNNNNN/embed',
        '@USER',
        '@USER/with_replies',
        '@USER/media',
    )
    ap = argparse.ArgumentParser(formatter_class=argparse.RawTextHelpFormatter)
    if sys.version_info < (3, 10):
        # https://bugs.python.org/issue9694
        ap._optionals.title = 'options'
    default_limit = 40
    ap.add_argument('--limit', metavar='N', type=pint, default=default_limit,
        help=f'maximum numer of posts to fetch (default: {default_limit})'
    )
    ap.add_argument('--debug', action='store_true', help=argparse.SUPPRESS)
    ap.add_argument('url', metavar='URL', help=str.join('\n', url_parser.templates))
    opts = ap.parse_args()
    if opts.debug:
        UserAgent.debug_level = 1
    url, _ = urllib.parse.urldefrag(opts.url)
    match = url_parser.parse(url)
    if match is None:
        ap.error('unsupported URL')
    sys.stdout.flush()
    with StdOut.install():
        if match.ident is None:
            process_user(match.domain, match.user,
                replies=bool(match.with_replies),
                media=bool(match.media),
                limit=opts.limit,
            )
        else:
            process_status(match.domain, match.ident,
                context=(not match.embed)
            )

def process_user(domain, account, *, replies=False, media=False, limit=1e999):
    api = f'https://{domain}/api/v1'
    q_account = urllib.parse.quote(account)
    user = wget_json(f'{api}/accounts/lookup?acct={q_account}')
    print('User:', fmt_user(user))
    if user.note:
        print()
        print(fmt_html(user.note))
    base_url = url = f'{api}/accounts/{user.id}/statuses';
    statuses = wget_json(f'{url}?pinned=true')
    print_statuses(statuses, pinned=True)
    limit -= len(statuses)
    page_limit = 40
    url = base_url
    if media:
        url += '?only_media=true'
    else:
        no_replies = str(not replies).lower()
        url += f'?exclude_replies={no_replies}'
    url += f'&limit={min(limit, page_limit)}'
    while limit > 0:
        statuses = wget_json(url)
        print_statuses(statuses)
        limit -= len(statuses)
        if limit > 0:
            return  # TODO: implement paging

def process_status(domain, ident, *, context=True):
    api = f'https://{domain}/api/v1'
    post = wget_json(f'{api}/statuses/{ident}')
    print_post(post)
    if context:
        context = wget_json(f'{api}/statuses/{ident}/context')
        print_statuses(context.descendants)

def print_statuses(statuses, *, pinned=False):
    for post in statuses:
        print()
        print('-' * html2text.config.BODY_WIDTH)
        print()
        print_post(post, pinned=pinned)

def normalize_lang(lang):
    if lang is None:
        return 'en'
    if lang.startswith('en-'):
        return 'en'
    return lang

def print_post(post, *, pinned=False):
    print('Location:', fmt_url(post.url))
    if pinned:
        print('Pinned: yes')
    print('From:', fmt_user(post.account))
    print('Date:', fmt_date(post.created_at))
    if normalize_lang(post.language) != 'en':
        print('Language:', post.language)
    if post.reblog:
        print('Reblog: yes')
    print()
    for att in post.media_attachments or ():
        print('*', fmt_url(att.url))
        print()
        text = att.description or ''
        text = wrap_text(text, indent='  ')
        if text:
            for line in text:
                print(line)
            print()
    if post.reblog:
        print_post(post.reblog)
    else:
        text = fmt_html(post.content)
        print(text)

def wrap_text(text, indent=''):
    text = text.splitlines()
    for line in text:
        line = textwrap.wrap(line,
            width=html2text.config.BODY_WIDTH,
            initial_indent=indent,
            subsequent_indent=indent,
        )
        yield str.join('\n', line)

def main():
    try:
        xmain()
    except BrokenPipeError:
        signal.signal(signal.SIGPIPE, signal.SIG_DFL)
        signal.raise_signal(signal.SIGPIPE)
        raise

if __name__ == '__main__':
    main()

# vim:ts=4 sts=4 sw=4 et
