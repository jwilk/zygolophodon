#!/usr/bin/env python3

# Copyright Â© 2022 Jakub Wilk <jwilk@jwilk.net>
# SPDX-License-Identifier: MIT

import argparse
import gzip
import http.client
import inspect
import io
import json
import re
import signal
import sys
import textwrap
import urllib.parse
import urllib.request

import html2text

0_0  # Python >= 3.6 is required

class StdOut(io.TextIOBase):

    def __init__(self):
        self._newlines = 0

    def _get_fp(self):
        for frameinfo in inspect.stack(context=0):
            if frameinfo.filename == http.client.__file__:
                # Redirect http.client's debug messages to stderr.
                return sys.__stderr__
        return sys.__stdout__

    def write(self, s):
        fp = self._get_fp()
        if fp is sys.__stdout__:
            if s == '':
                return
            if s == '\n':
                if self._newlines == 2:
                    return
                self._newlines += 1
            else:
                self._newlines = int(s[-1] == '\n')
        fp.write(s)

    def flush(self):
        self._get_fp().flush()

class UserAgent():

    headers = {
        'User-Agent': 'zygolophodon (https://github.com/jwilk/zygolophodon)',
        'Accept-Encoding': 'gzip',
    }
    debug_level = 0

    @classmethod
    def _build_opener(cls):
        # TODO: Get rid of this function once
        # <https://github.com/python/cpython/issues/99352> is fixed.
        handlers = [
            Handler(debuglevel=cls.debug_level)
            for Handler in [urllib.request.HTTPHandler, urllib.request.HTTPSHandler]
        ]
        return urllib.request.build_opener(*handlers)

    @classmethod
    def get(cls, url):
        headers = dict(cls.headers)
        request = urllib.request.Request(url, headers=headers)
        opener = cls._build_opener()
        with opener.open(request) as fp:
            content_encoding = fp.getheader('Content-Encoding', 'identity')
            data = fp.read()
        if content_encoding == 'gzip':
            return gzip.decompress(data)
        elif content_encoding == 'identity':
            return data
        else:
            raise RuntimeError(f'unexpected Content-Encoding: {content_encoding!r}')

    @classmethod
    def get_json(cls, url):
        data = cls.get(url)
        return json.loads(data, object_hook=DictProxy)

wget = UserAgent.get
wget_json = UserAgent.get_json

class DictProxy(object):

    def __init__(self, d):
        self._d = d

    def __getattr__(self, attr):
        return self._d[attr]

def fmt_user(account):
    return f'{account.display_name} <{account.url}>'.lstrip()

def fmt_date(d):
    d = re.sub(r'[.]\d+', '', d)
    d = d.replace('T', ' ')
    return d

def fmt_html(html):
    html2md = html2text.HTML2Text()
    html2md.unicode_snob = True
    text = html2md.handle(html)
    return text.strip('\n')

def xmain():
    urls = ['@USER', '@USER/with_replies', '@USER/media', '@USER/NNNNNN']
    urls = [f'https://DOMAIN/{url}' for url in urls]
    ap = argparse.ArgumentParser(formatter_class=argparse.RawTextHelpFormatter)
    if sys.version_info < (3, 10):
        # https://bugs.python.org/issue9694
        ap._optionals.title = 'options'
    ap.add_argument('--debug', action='store_true', help=argparse.SUPPRESS)
    ap.add_argument('url', metavar='URL', help=str.join('\n', urls))
    opts = ap.parse_args()
    if opts.debug:
        UserAgent.debug_level = 1
    url, _ = urllib.parse.urldefrag(opts.url)
    match = re.fullmatch(r'https://([^/]+)/@([^/]+)(?:/([0-9]+)|/(with_replies)|/(media))?', url)
    if not match:
        ap.error('unsupported URL')
    sys.stdout = StdOut()
    (domain, account, ident, with_replies, media) = match.groups()
    if ident is None:
        process_user(domain, account, replies=bool(with_replies), media=bool(media))
    else:
        process_status(domain, ident)

def process_user(domain, account, *, replies=False, media=False):
    api = f'https://{domain}/api/v1'
    q_account = urllib.parse.quote(account)
    user = wget_json(f'{api}/accounts/lookup?acct={q_account}')
    print('User:', fmt_user(user))
    if user.note:
        print()
        print(fmt_html(user.note))
    url = f'{api}/accounts/{user.id}/statuses';
    statuses = wget_json(f'{url}?pinned=true')
    print_statuses(statuses, pinned=True)
    if media:
        url += '?only_media=true'
    else:
        no_replies = str(not replies).lower()
        url += f'?exclude_replies={no_replies}'
    url += '&limit=40'
    # TODO: implement paging
    statuses = wget_json(url)
    print_statuses(statuses)

def process_status(domain, ident):
    api = f'https://{domain}/api/v1'
    post = wget_json(f'{api}/statuses/{ident}')
    print_post(post)
    context = wget_json(f'{api}/statuses/{ident}/context')
    print_statuses(context.descendants)

def print_statuses(statuses, *, pinned=False):
    for post in statuses:
        print()
        print('-' * html2text.config.BODY_WIDTH)
        print()
        print_post(post, pinned=pinned)

def normalize_lang(lang):
    if lang is None:
        return 'en'
    if lang.startswith('en-'):
        return 'en'
    return lang

def print_post(post, *, pinned=False):
    print('Location:', post.url)
    if pinned:
        print('Pinned: yes')
    print('From:', fmt_user(post.account))
    print('Date:', fmt_date(post.created_at))
    if normalize_lang(post.language) != 'en':
        print('Language:', post.language)
    if post.reblog:
        print('Reblog: yes')
    print()
    for att in post.media_attachments or ():
        print('*', att.url)
        print()
        text = att.description or ''
        text = wrap_text(text, indent='  ')
        if text:
            for line in text:
                print(line)
            print()
    if post.reblog:
        print_post(post.reblog)
    else:
        text = fmt_html(post.content)
        print(text)

def wrap_text(text, indent=''):
    text = text.splitlines()
    for line in text:
        line = textwrap.wrap(line,
            width=html2text.config.BODY_WIDTH,
            initial_indent=indent,
            subsequent_indent=indent,
        )
        yield str.join('\n', line)

def main():
    try:
        xmain()
    except BrokenPipeError:
        signal.signal(signal.SIGPIPE, signal.SIG_DFL)
        signal.raise_signal(signal.SIGPIPE)
        raise

if __name__ == '__main__':
    main()

# vim:ts=4 sts=4 sw=4 et
